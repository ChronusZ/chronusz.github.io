---
layout: default
title: "Trusted Storage Units"
date: 2017-07-24
use_math: true
---

# Message Optimization with Trusted Storage Units

This note is just tossing around ideas for optimization of parliamentary consensus.

The main reason we are (i.e., David and Stefan are) still considering doing the establish phase before parliamentary consensus is to make the protocol more efficient by ensuring that in most cases all the nodes will already know the transaction set each hash belongs to, thus enabling us to effectively just run parliamentary consensus using hashes, and in most cases no costly extra transmission of transaction sets would need to occur.

I'm still somewhat fuzzy on how the establish phase takes care of learning about new transaction sets, so I'm not sure how costly the transmission is there; just intuitively I would imagine that there must be at least a few different transaction sets in circulation at the start usually, so probably every node needs to learn at least a couple of whole new transaction sets. Thus the total number of "large" messages (i.e., messages on the size scale of whole transaction sets) transmitted is probably at least around $$2N$$ with $$N$$ nodes. These are just incredibly loose, intuitive guesses though, so please correct me if somehow the number of large messages transmitted is cleverly kept smaller.

I came up with a way to do parliamentary consensus without an establish phase such that in the common scenario the total number of large messages is just $$N+B\cdot T$$, where $$N$$ is the total number of nodes, $$B$$ is the total number of active (i.e., not crashed) candidates, and $$T$$ is the number of "trusted storage units", which I'll explain below. In practice, I imagine $$N$$ will be quite a bit larger than $$B$$ and *much* larger than $$T$$, so I think these are quite reasonable message complexities.

Some details are still unrefined, but basically the idea goes as follows: We (or a bunch of diverse, trusted other groups) set up a group of $$T$$ servers which are referred to as **trusted storage units**. Let $$f$$ be the number of allowed Byzantine failures among the storage units. The protocol works as long as $$T\geqslant 2f+1$$. In fact, even if the number of failures goes above $$f$$, there is no risk of causing a fork; however, if the number of failures is higher than $$f$$, then termination could be blocked.

Trusted storage units should be basically agreed upon; it's not very problematic in practice if there is some disagreement on the set of storage units, but for optimal efficiency it's best if everyone agrees, since disagreement just leads to wasted file transfers. Probably the best way to change the trusted storage units is through something like the ballot amendment protocol.

Basically the idea is that the trusted storage units regulate distribution of transaction sets while the rest of the nodes just do consensus using hashes. When a candidate sends out its proposal, it turns its transaction set into a Merkle tree and uses the root hash as its proposal in parliamentary consensus. Then it begins uploading its transaction set to each of the trusted storage units.

When a validator accepts a reliable broadcast from a candidate, it asks the trusted storage units if they have successfully received the relevant entire transaction set. Only after receiving $$f+1$$ confirmations, then it votes yes on the relevant binary agreement instance; this ensures that some nonfaulty storage unit has received the entire transaction set.

Once parliamentary consensus has terminated and a node knows the root hash of the proposal of every node in the council, it makes a request from the trusted storage units by sending them the root hashes all combined into a single message (which, with a reasonable council size, will be quite small). When a trusted storage unit receives a request, it checks to see if it received transaction sets from all the nodes mentioned. If not, it sends a failure message back listing the subset of nodes which they received. If the trusted storage unit *has* received all the transaction sets mentioned, it creates a new file which contains every transaction in the union of the relevant transaction sets, and a tag at the end of each transaction listing the keys of which council members included that transaction in their proposal (if the keys are sorted in a deterministic way, then one could just use a single bit for each council member to show if it included the relevant transaction, making the tag length reasonably small). It then creates a (binary) Merkle tree out of this *new* set and returns the root hash to the requesting node, along with the branch leading to the maximal leaf.

When the requesting node receives a root hash+maximal branch from a trusted storage unit, it first verifies the validity of the branch. Let $$k$$ be the number of entries there are in the set, computed using the maximal branch. Since the Merkle tree is binary, the maximal branch must be a bunch of rights, ending possibly on a left; thus the most a malicious storage unit can do is send the branch corresponding to the *second* highest leaf, so $$k$$ is off by at most $$1$$. Pick a random number $$i$$ from $$0$$ to $$k$$, and request that the storage unit sends the branch corresponding to the $$i$$-th leaf.

The storage unit then returns the requested branch along with branches from each council member's transaction set that prove that the tag line is correct.

Finally, the requesting node verifies the requested branch against the storage unit's root hash, and verifies all the other branches against the root hashes we got from parliamentary consensus. If all this checks out, then we can be reasonably confident that the root hash the storage units gave us is mostly legitimate, so we can then download that set using BitTorrent or something.

After we've downloaded the set, we have all the information needed to reconstruct each council member's transaction set using the tags. We can then verify the transaction sets we've constructed against the root hashes we have, and if they match we're all set (no pun intended). If it doesn't match, then either 1) there was a bug with the way we reconstructed the transaction sets, or 2) the sender was malicious, but they screwed only with a few entries to avoid being caught by the previous test. In the latter case, we can basically try the same thing again with a different trusted storage unit. Because the original file passed the safety check before, we probably already have most of the branches downloaded. Thus if we begin downloading a new file, we can compare branches against the branches we already have, and only download from the swarm the branches we don't know, which should be much fewer in general.

The probability that we download a set from a storage unit is directly proportional to the number of correct elements of that set, so even if we get unlucky and pick out a malicious node to download from, we expect that at least $$\frac{1}{3}$$ of each download to be valid. Thus even in the worst case where we continually pick malicious nodes to download from, the extraneous data we download on the $$n$$-th attempt is expected to be $$\frac{2^n}{3^n}$$; summing this infinite series, one sees that even in the absolute worst case scenario, malicious nodes can only effectively make us download an extra two transaction sets. Because of the confirmations at the beginning, we know there must be at least one honest, live storage unit, so eventually we know that we can get the whole file; until that point, we might waste some download time downloading from a malicious unit, but the overhead from this is not terrible by the analysis above. Checking more branches could reduce this overhead even further, but at some point of course the cost of checking branches becomes an overhead itself. In practice one might do a ratcheted safety scheme where each time we download a failed set, we increase the number of safety checks. Note as well that in this case it is very easy to recognize malicious behavior, so at worst a malicious storage unit can only add a slight overhead for a single round before all the nodes learn that it's malicious and begin avoiding it.
